{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2209261 Basic Programming NLP\n",
    "## Lab 12 : NLP (Part II Large Language Model)\n",
    "## Done by : 6730084521 Chatrphol Ovanonchai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cT7y--9LUd8"
   },
   "source": [
    "# 1. Generate a Jokes Dataset with an LLM\n",
    "\n",
    "Write a Python script that calls the Gemini API to generate a small jokes dataset based on a user-provided topic and number of jokes, then returns the results as a pandas DataFrame.\n",
    "\n",
    "## Functional Requirements\n",
    "1. **Inputs**\n",
    "   - `topic` (string), e.g., `\"computers\"`, `\"Thai food\"`.\n",
    "   - `n_jokes` (int), e.g., `20`.\n",
    "\n",
    "2. **LLM Call (Gemini API)**\n",
    "   - Prompt Gemini to generate `n_jokes` short, family-friendly jokes about the given topic.\n",
    "   - Ask Gemini to return the output in **strict JSON** format with the following structure.\n",
    "\n",
    "3. **Expected Output Schema**\n",
    "   | Column | Type | Description |\n",
    "   |---------|------|--------------|\n",
    "   | id | int | Index number (1..n) |\n",
    "   | topic | str | The topic used |\n",
    "   | joke | str | The joke text |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install libraries\n",
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "executionInfo": {
     "elapsed": 7041,
     "status": "ok",
     "timestamp": 1761649095766,
     "user": {
      "displayName": "jakapun ta",
      "userId": "02776561496860281329"
     },
     "user_tz": -420
    },
    "id": "aadbd38d",
    "outputId": "81f75b99-99df-4ed2-f2b7-f8b80752baad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you want to learn about cats and dogs.\n",
      "\n",
      "**Generative Model: The Artist who learns to DRAW cats and dogs.**\n",
      "\n",
      "A generative model tries to **understand how to create** examples of data. It learns the underlying patterns and characteristics of the data so well that it can then **generate new, similar examples**.\n",
      "\n",
      "*   **Think of it like this:** A generative model is like an artist who studies thousands of pictures of cats and dogs. They learn what makes a cat look like a cat (pointy ears, whiskers, slitted eyes) and what makes a dog look like a dog (floppy ears, wagging tail, different snout shapes).\n",
      "*   **Its goal:** To be able to **draw a brand new cat** or **draw a brand new dog** that looks realistic, even if it's a breed it's never seen before.\n",
      "*   **What it learns:** It learns the **probability of seeing a particular feature given the class** (e.g., the probability of having pointy ears given it's a cat) and the **probability of seeing a particular class** (e.g., how common cats are versus dogs).\n",
      "\n",
      "**Discriminative Model: The Judge who learns to TELL cats and dogs APART.**\n",
      "\n",
      "A discriminative model, on the other hand, focuses on **learning the boundaries between different classes** of data. It doesn't necessarily learn how to create the data itself, but rather how to **distinguish** one class from another.\n",
      "\n",
      "*   **Think of it like this:** A discriminative model is like a judge who looks at pictures of cats and dogs and learns the key differences that help them decide which is which. They don't need to know how to draw a cat, just how to tell if a given picture *is* a cat.\n",
      "*   **Its goal:** To be able to **look at a new picture and say, \"This is a cat\" or \"This is a dog.\"**\n",
      "*   **What it learns:** It learns the **probability of a class given the features** (e.g., the probability that an image is a cat given its visual features). It directly tries to find the \"decision boundary\" that separates the classes.\n",
      "\n",
      "---\n",
      "\n",
      "**Here's a simple analogy to summarize:**\n",
      "\n",
      "*   **Generative Model:** Learns to **make** them. (Like an artist)\n",
      "*   **Discriminative Model:** Learns to **tell them apart**. (Like a judge)\n",
      "\n",
      "**Key Differences in a Nutshell:**\n",
      "\n",
      "| Feature           | Generative Model                                  | Discriminative Model                               |\n",
      "| :---------------- | :------------------------------------------------ | :------------------------------------------------- |\n",
      "| **Primary Goal**  | Generate new data samples.                        | Classify or predict labels for given data.         |\n",
      "| **What it Learns**| The distribution of the data (how to create it). | The decision boundary between classes.             |\n",
      "| **\"How\" it works**| Models P(X, Y) or P(X|Y) and P(Y).                | Models P(Y|X) directly.                            |\n",
      "| **Examples**      | GANs, Variational Autoencoders (VAEs), Naive Bayes, Hidden Markov Models (HMMs) | Logistic Regression, Support Vector Machines (SVMs), Decision Trees, Neural Networks for classification |\n",
      "| **Use Cases**     | Image generation, text generation, data augmentation. | Image classification, spam detection, sentiment analysis. |\n",
      "\n",
      "In essence, generative models are about **understanding the essence of the data** to create more of it, while discriminative models are about **finding clear dividing lines** to make predictions.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "api_key = \"AIzaSyBoZ3ltxyq3IZKksNGB19SvNcH6S2nPRyQ\"\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n",
    "\n",
    "prompt = \"Explain the difference between a Generative model and a Discriminative model in simple terms.\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Department of Electrical Engineering at Chulalongkorn University has a rich and significant history, mirroring the development of electrical engineering as a discipline in Thailand. Here's a breakdown of its evolution:\n",
      "\n",
      "**Early Beginnings and the Foundation of Electrical Engineering Education (Pre-1950s):**\n",
      "\n",
      "* **Inception of Engineering at Chulalongkorn University:** Chulalongkorn University, founded in 1917, was the first institution of higher learning in Thailand. Its early focus was on broader scientific and professional fields.\n",
      "* **The Need for Technical Expertise:** As Thailand began to modernize and embrace new technologies, particularly in the early to mid-20th century, there was a growing demand for skilled engineers. Electricity was becoming increasingly crucial for infrastructure development, industry, and communication.\n",
      "* **Initial Steps Towards Electrical Training:** While a dedicated \"Electrical Engineering\" department didn't exist from the outset, foundational electrical-related subjects were likely integrated into broader engineering curricula, possibly within a Mechanical Engineering or general Applied Science framework. The focus would have been on practical skills and basic principles to support the nascent electrical infrastructure of the country.\n",
      "\n",
      "**The Formal Establishment of the Department of Electrical Engineering (1950s):**\n",
      "\n",
      "* **The Birth of a Dedicated Discipline:** The 1950s marked a pivotal period for the formal establishment of specialized engineering disciplines in Thailand. Recognizing the growing importance of electricity, Chulalongkorn University took a decisive\n"
     ]
    }
   ],
   "source": [
    "## Optional : Tuning output (TEst with prompt)\n",
    "prompt = \"Explain history of department of Elecrial Engineering , Chulalongkorn University \"\n",
    "\n",
    "# Define the generation configuration\n",
    "generation_config = {\n",
    "    \"temperature\": 0.7,  # A higher temperature for creativity\n",
    "    \"max_output_tokens\": 300 # Keep the story relatively short\n",
    "}\n",
    "\n",
    "# Make the API call with the configuration\n",
    "try:\n",
    "    response = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=generation_config\n",
    "    )\n",
    "    print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c36418c1"
   },
   "source": [
    "## Define function for joke generation\n",
    "\n",
    "### Subtask:\n",
    "Create a Python function that takes the topic and number of jokes as input, calls the Gemini API to generate jokes in JSON format, and returns the JSON response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18e7a607"
   },
   "source": [
    "**Reasoning**:\n",
    "Define the Python function to generate jokes using the Gemini API, construct the prompt, call the API, extract the JSON response, and return it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1761645313523,
     "user": {
      "displayName": "jakapun ta",
      "userId": "02776561496860281329"
     },
     "user_tz": -420
    },
    "id": "ef7fe529"
   },
   "outputs": [],
   "source": [
    "# import json parse libraries\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "def generate_jokes_from_gemini(topic: str, n_jokes: int):\n",
    "\n",
    "    # Step 1 : create prompt f-string \n",
    "    prompt = f\"Generate jokes about {topic} with quantity of {n_jokes} jokes , need it in JSON format having id , topics (value = {topic}) and joke keys\"\n",
    "    \n",
    "    # Step 2 : Tuning output with generation_config\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.72,  # A higher temperature for creativity\n",
    "        \"max_output_tokens\": 500 , # Keep the story relatively short\n",
    "        \"response_mime_type\": \"application/json\" # return JSON Type\n",
    "    }\n",
    "    \n",
    "    # Step 3 : generate content with tuned output\n",
    "    response = model.generate_content(prompt , generation_config = generation_config)\n",
    "    \n",
    "    # Step 4 : return as response.text (JSON Format)\n",
    "    data = response.text\n",
    "    return data # JSON String\n",
    "\n",
    "def parse_jokes_json_to_dataframe(jokes_json):\n",
    "    \n",
    "    # Step 1 : loads JSON String to list/dict\n",
    "    jokes_data = json.loads(jokes_json)         # string ‚Üí Python list/dict\n",
    "    \n",
    "    # Step 2 ; using json_normalize to convert string to dataframe\n",
    "    output_df = json_normalize(jokes_data, sep=\"_\")    # flatten JSON\n",
    "    \n",
    "    # Step 3 : return dataframe\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 2603,
     "status": "ok",
     "timestamp": 1761645320721,
     "user": {
      "displayName": "jakapun ta",
      "userId": "02776561496860281329"
     },
     "user_tz": -420
    },
    "id": "2130ba07",
    "outputId": "d6a230d3-a8f6-4d69-b922-9b7725e97e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"topics\": \"animals\",\n",
      "    \"joke\": \"Why don't scientists trust atoms? Because they make up everything! (Just kidding, that's a science joke. Here's an animal one:) What do you call a lazy kangaroo? Pouch potato!\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"topics\": \"animals\",\n",
      "    \"joke\": \"What do you call a fish with no eyes? Fsh!\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 3,\n",
      "    \"topics\": \"animals\",\n",
      "    \"joke\": \"Why did the scarecrow win an award? Because he was outstanding in his field! (Okay, that's not an animal. How about this:) What do you get when you cross a snowman and a vampire? Frostbite!\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 4,\n",
      "    \"topics\": \"animals\",\n",
      "    \"joke\": \"Why did the bicycle fall over? Because it was two tired! (Still not an animal. Try this:) What do you call a bear with no teeth? A gummy bear!\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 5,\n",
      "    \"topics\": \"animals\",\n",
      "    \"joke\": \"Why was the math book sad? Because it had too many problems! (This is hard! Let's get back to animals:) What do you call a group of musical whales? An orca-stra!\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topics</th>\n",
       "      <th>joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>animals</td>\n",
       "      <td>Why don't scientists trust atoms? Because they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>animals</td>\n",
       "      <td>What do you call a fish with no eyes? Fsh!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>animals</td>\n",
       "      <td>Why did the scarecrow win an award? Because he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>animals</td>\n",
       "      <td>Why did the bicycle fall over? Because it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>animals</td>\n",
       "      <td>Why was the math book sad? Because it had too ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   topics                                               joke\n",
       "0   1  animals  Why don't scientists trust atoms? Because they...\n",
       "1   2  animals         What do you call a fish with no eyes? Fsh!\n",
       "2   3  animals  Why did the scarecrow win an award? Because he...\n",
       "3   4  animals  Why did the bicycle fall over? Because it was ...\n",
       "4   5  animals  Why was the math book sad? Because it had too ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic = \"animals\"\n",
    "n_jokes = 5\n",
    "\n",
    "jokes_json = generate_jokes_from_gemini(topic, n_jokes)\n",
    "print(jokes_json)\n",
    "\n",
    "jokes_df = parse_jokes_json_to_dataframe(jokes_json)\n",
    "\n",
    "display(jokes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 1821,
     "status": "ok",
     "timestamp": 1761645322549,
     "user": {
      "displayName": "jakapun ta",
      "userId": "02776561496860281329"
     },
     "user_tz": -420
    },
    "id": "bf13287e",
    "outputId": "fb11121b-5e9a-4243-88f6-a3ecc2a8e8a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topics</th>\n",
       "      <th>joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>science</td>\n",
       "      <td>Why did the biologist break up with the physic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>science</td>\n",
       "      <td>What do you call a lazy kangaroo? Pouch potato.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>science</td>\n",
       "      <td>Why don't scientists trust atoms? Because they...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   topics                                               joke\n",
       "0   1  science  Why did the biologist break up with the physic...\n",
       "1   2  science    What do you call a lazy kangaroo? Pouch potato.\n",
       "2   3  science  Why don't scientists trust atoms? Because they..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic = \"science\"\n",
    "n_jokes = 3\n",
    "\n",
    "jokes_json = generate_jokes_from_gemini(topic, n_jokes)\n",
    "jokes_df = parse_jokes_json_to_dataframe(jokes_json)\n",
    "\n",
    "display(jokes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2rUV7e1VR7B"
   },
   "source": [
    "# Task 2 ‚Äî Classify Sentiment with Gemini (LLM)\n",
    "\n",
    "##  Goal\n",
    "Use the **Gemini API** to classify the sentiment of social-media messages from the **`wisesight_sentiment`** dataset, then evaluate model performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Task 2.1 ‚Äî Sentiment Classification with LLM\n",
    "1. Call the **Gemini API** to classify sentiment for each message in the dataset.\n",
    "2. **Batch processing recommended**:  \n",
    "   - Send messages in batches (e.g., **20 rows at a time**) to reduce overhead.\n",
    "3. The model‚Äôs **output must contain only the sentiment label**  \n",
    "   - No explanation, reasoning, or extra text.\n",
    "   - Example expected outputs:  \n",
    "     - `\"positive\"`  \n",
    "     - `\"neutral\"`  \n",
    "     - `\"negative\"`\n",
    "4. Store the predicted sentiment label in a **new column** in your DataFrame (e.g., `pred_sentiment`).\n",
    "\n",
    "---\n",
    "\n",
    "## Task 2.2 ‚Äî Evaluate Performance\n",
    "Write a function to compute the following metrics:\n",
    "\n",
    "### **Accuracy**\n",
    "Measures the proportion of correctly predicted labels.\n",
    "\n",
    "```\n",
    "accuracy = (number_of_correct_predictions) / (total_number_of_predictions)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 27421,
     "status": "ok",
     "timestamp": 1761649227186,
     "user": {
      "displayName": "jakapun ta",
      "userId": "02776561496860281329"
     },
     "user_tz": -420
    },
    "id": "8tL3Ap7AW_mG",
    "outputId": "44209f9f-898e-4e3d-dacc-fb51ecc1d88d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampled_sentiment_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m display(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sampled_sentiment_dataset.csv\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1761649523883,
     "user": {
      "displayName": "jakapun ta",
      "userId": "02776561496860281329"
     },
     "user_tz": -420
    },
    "id": "5gwz4q63ZNkL",
    "outputId": "5202dc0a-f016-4a90-d533-c627f18ab0fc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create column \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_sentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# test prompt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclassify_batch\u001b[39m(texts):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# ----- Simple prompt -----\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# create column \n",
    "df['pred_sentiment'] = None\n",
    "\n",
    "# test prompt\n",
    "def classify_batch(texts):\n",
    "    # ----- Simple prompt -----\n",
    "    prompt = f\"\"\"\n",
    "                Classify the sentiment of each text as: pos, neu, or neg.\n",
    "                Return only a JSON list of labels in the same order.\n",
    "\n",
    "                Texts:\n",
    "                {texts}\n",
    "              \"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    return eval(response.text)  # [\"pos\", \"neu\", \"neg\", ...]\n",
    "\n",
    "# ----- Run batch 20 rows -----\n",
    "batch_size = 20\n",
    "predictions = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df['full_text'][i:i+batch_size].tolist()\n",
    "    pred = classify_batch(batch)\n",
    "    predictions.extend(pred)\n",
    "\n",
    "df['pred_sentiment'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡∏Å‡∏π‡∏à‡∏∞‡πÑ‡∏õ‡∏î‡∏π‡∏î‡πÉ‡∏ô‡πÄ‡∏£‡∏∑‡∏≠‡∏î‡∏≥‡∏ô‡πâ‡∏≥‡∏Ç‡∏≠‡∏á‡∏ô‡∏≤‡∏¢‡∏Å üòÖ</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°!! ‡∏ù‡∏∂‡∏Å‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏•‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö ‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏≤‡∏û‡∏ö...</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå‡∏°‡∏µ‡∏´‡∏°‡πâ‡∏≠‡∏ô‡πâ‡∏≥‡∏ã‡∏∏‡∏õ4‡∏ä‡πà‡∏≠‡∏á‡πÑ‡∏´‡∏°‡∏Ñ‡πà‡∏∞</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ShowDC ‡∏á‡∏≤‡∏ô‡∏î‡∏µ ‡πÄ‡∏£‡∏≤‡πÄ‡∏Ñ‡∏¢‡∏¢‡∏¢üëçüëçüëç</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡∏õ‡∏õ‡∏õ‡∏õ.))</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>‡∏Ç‡∏ô‡πÄ‡∏™‡∏î‡πÑ‡∏á</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∏‡πà‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö Honda Civic ‡∏°‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏ß‡∏•‡∏≤</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>‡∏™‡∏á‡∏™‡∏≤‡∏£‡πÑ‡∏≠‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å‡∏≠‡∏∞‡∏î‡∏¥</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡πÄ‡∏ö‡∏•‡πá‡∏Å ‡∏£‡∏™‡∏ù‡∏≤‡∏î‡πÄ‡∏ã‡∏•‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏Ç‡∏ß‡∏î‡∏ô‡∏∂‡∏á</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                texts category  \\\n",
       "0                       ‡∏Å‡∏π‡∏à‡∏∞‡πÑ‡∏õ‡∏î‡∏π‡∏î‡πÉ‡∏ô‡πÄ‡∏£‡∏∑‡∏≠‡∏î‡∏≥‡∏ô‡πâ‡∏≥‡∏Ç‡∏≠‡∏á‡∏ô‡∏≤‡∏¢‡∏Å üòÖ      neu   \n",
       "1   ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°!! ‡∏ù‡∏∂‡∏Å‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏•‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö ‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏≤‡∏û‡∏ö...      neu   \n",
       "2                    ‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå‡∏°‡∏µ‡∏´‡∏°‡πâ‡∏≠‡∏ô‡πâ‡∏≥‡∏ã‡∏∏‡∏õ4‡∏ä‡πà‡∏≠‡∏á‡πÑ‡∏´‡∏°‡∏Ñ‡πà‡∏∞      neu   \n",
       "3                            ShowDC ‡∏á‡∏≤‡∏ô‡∏î‡∏µ ‡πÄ‡∏£‡∏≤‡πÄ‡∏Ñ‡∏¢‡∏¢‡∏¢üëçüëçüëç      pos   \n",
       "4                                             ‡∏õ‡∏õ‡∏õ‡∏õ.))      neu   \n",
       "..                                                ...      ...   \n",
       "95                                            ‡∏Ç‡∏ô‡πÄ‡∏™‡∏î‡πÑ‡∏á      neu   \n",
       "96  ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∏‡πà‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö Honda Civic ‡∏°‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ...      pos   \n",
       "97                                           ‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏ß‡∏•‡∏≤      neg   \n",
       "98                                 ‡∏™‡∏á‡∏™‡∏≤‡∏£‡πÑ‡∏≠‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å‡∏≠‡∏∞‡∏î‡∏¥      neu   \n",
       "99                ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡πÄ‡∏ö‡∏•‡πá‡∏Å ‡∏£‡∏™‡∏ù‡∏≤‡∏î‡πÄ‡∏ã‡∏•‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏Ç‡∏ß‡∏î‡∏ô‡∏∂‡∏á      neu   \n",
       "\n",
       "    predicted_labels  pred_sentiment  \n",
       "0                  0               0  \n",
       "1                  0               0  \n",
       "2                  0               0  \n",
       "3                  0               0  \n",
       "4                  0               0  \n",
       "..               ...             ...  \n",
       "95                 0               0  \n",
       "96                 0               0  \n",
       "97                 0               0  \n",
       "98                 0               0  \n",
       "99                 0               0  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNO6js7K7WY2IrYliEmztmo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
